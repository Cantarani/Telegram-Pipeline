{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Projeto - Pipeline de dados do Telegram","metadata":{}},{"cell_type":"markdown","source":"## Contexto","metadata":{}},{"cell_type":"markdown","source":"### Chatbot\nUm chatbot é um tipo de software que interage com usuários através de conversas automatizadas em plataformas de mensagens. Uma aplicação comum de chatbots é o seu uso no atendimento ao cliente, onde, de maneira geral, ajudam clientes a resolver problemas ou esclarecer dúvidas recorrentes antes mesmo que um atendente humano seja acionado.","metadata":{}},{"cell_type":"markdown","source":"### Telegram \nTelegram é uma plataforma de mensagens instantâneas freeware (distribuído gratuitamente) e, em sua maioria, open source. É muito popular entre desenvolvedores por ser pioneiro na implantação da funcionalidade de criação de chatbots, que, por sua vez, permitem a criação de diversas automações. ","metadata":{}},{"cell_type":"markdown","source":"### Arquitetura\nA arquitetura proposta é dividida em duas: transacional, no Telegram, onde os dados são produzidos, e analítica, na Amazon Web Services (AWS), onde os dados são analisados.","metadata":{}},{"cell_type":"markdown","source":"* **Telegram**\n\nO Telegram representa a fonte de dados transacionais. Mensagens enviadas por usuários em um grupo são capturadas por um bot e redirecionadas via webhook do backend do aplicativo para um endpoint (endereço web que aceita requisições HTTP) exposto pelo AWS API Gateway. As mensagens trafegam no corpo ou payload da requisição.","metadata":{}},{"cell_type":"markdown","source":"* **AWS | Ingestão**\n\nUma requisição HTTP com o conteúdo da mensagem em seu payload é recebia pelo AWS API Gateway que, por sua vez, as redireciona para o AWS Lambda, servindo assim como seu gatilho. Já o AWS Lambda recebe o payload da requisição em seu parâmetro event, salva o conteúdo em um arquivo no formato JSON (original, mesmo que o payload) e o armazena no AWS S3 particionado por dia.","metadata":{}},{"cell_type":"markdown","source":"* **AWS | ETL**\n\nUma vez ao dia, o AWS Event Bridge aciona o AWS Lambda que processa todas as mensagens do dia anterior (atraso de um dia ou D-1), denormaliza o dado semi-estruturado típico de arquivos no formato JSON, salva o conteúdo processado em um arquivo no formato Apache Parquet e o armazena no AWS S3 particionado por dia.","metadata":{}},{"cell_type":"markdown","source":"* **AWS | Apresentação**\n\nPor fim, uma tabela do AWS Athena é apontada para o bucket do AWS S3 que armazena o dado processado: denormalizado, particionado e orientado a coluna. Profissionais de dados podem então executar consultas analíticas (agregações, ordenações, etc.) na tabela utilizando o SQL para a extração de insights.","metadata":{}},{"cell_type":"markdown","source":"## Telegram","metadata":{}},{"cell_type":"markdown","source":"O Telegram representa a fonte transacional de dados do pipelne. Nesta etapa criei um bot e o adicionei à um grupo recém criado. O bot então captará todas as mensagens enviadas no grupo. As mensagens pode ser acessadas através da API (application programming interface) de bots dos Telegram (documentação neste link).","metadata":{}},{"cell_type":"markdown","source":"## Mensagem\n\nUma mensagem recuperada via API é um dado semi-estruturado no formato JSON com algumas chaves mandatórias e diversas chaves opcionais, estas últimas presentes (ou não) dependendo do tipo da mensagem. Por exemplo, mensagens de texto apresentam a chave `text` enquanto mensagens de áudio apresentam a chave `audio`. Neste projeto foquie apenas em mensagens do tipo texto, ou seja, o código vai ingerir as chaves mandatórias e a chave `text`.","metadata":{}},{"cell_type":"markdown","source":"* Exemplo","metadata":{}},{"cell_type":"code","source":"{\n    \"update_id\": 123,\n    \"message\": {\n        \"message_id\": 1,\n        \"from\": {\n            \"id\": 321,\n            \"is_bot\": false,\n            \"first_name\": \"Andre\"\n        },\n        \"chat\": {\n            \"id\": -789,\n            \"type\": \"group\"\n        },\n        \"date\": 1640995200,\n        \"text\": \"Ola, mundo!\"\n    }\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Wrangling ","metadata":{}},{"cell_type":"markdown","source":"Para denormalizar o conteúdo da mensagem semi-estruturado no formato JSON utilizando apenas Python nativo, ou seja, sem o auxílio de pacotes, como Pandas, utilizei um laço de repetição para varrer todas as chaves do arquivo e selecionar apenas as de interesse. \n\nCaso a mensagem não possua a chave `text`, ela será criada com o valor igual a `None`. Além disso, vamos adicionei duas chaves de tempo para indicar o momento em que o dado foi processado: `context_date` e `context_timestamp`.","metadata":{}},{"cell_type":"code","source":"import json\n\nwith open('telegram.json', mode='r', encoding='utf8') as fp:\n  data = json.load(fp)\n  data = data[\"message\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\n\ndate = datetime.now().strftime('%Y-%m-%d')\ntimestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\nparsed_data = dict()\n\nfor key, value in data.items():\n\n    if key == 'from':\n        for k, v in data[key].items():\n            if k in ['id', 'is_bot', 'first_name']:\n              parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n\n    elif key == 'chat':\n        for k, v in data[key].items():\n            if k in ['id', 'type']:\n              parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n\n    elif key in ['message_id', 'date', 'text']:\n        parsed_data[key] = [value]\n\nif not 'text' in parsed_data.keys():\n  parsed_data['text'] = [None]\n\nparsed_data['context_date'] = [date]\nparsed_data['context_timestamp'] = [timestamp]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Por fim, utilizei o pacote Python PyArrow para criar uma tabela com os dados processado que, posteriormente, pode ser facilmente persistida em um arquivo no formato Apache Parquet.","metadata":{}},{"cell_type":"code","source":"import pyarrow as pa\n\ntable = pa.Table.from_pydict(mapping=parsed_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ingestão","metadata":{}},{"cell_type":"markdown","source":"A etapa de ingestão é responsável, como seu o próprio nome diz, pela ingestão dos dados transacionais em ambientes analíticos. De maneira geral, o dado ingerido é persistido no formato mais próximo do original, ou seja, nenhuma transformação é realizada em seu conteúdo ou estrutura (schema). Como exemplo, dados de uma API web que segue o formato REST (representational state transfer) são entregues, logo, persistidos, no formato JSON.","metadata":{}},{"cell_type":"markdown","source":"No projeto, as mensagens capturadas pelo bot podem ser ingeridas através da API web de bots do Telegram, portanto são fornecidos no formato JSON. Como o Telegram retém mensagens por apenas 24h em seus servidores, a ingestão via streaming é a mais indicada. Para que seja possível esse tipo de ingestão seja possível, utilizei um `webhook`, ou seja, redirecionei as mensagens automaticamente para outra API web.","metadata":{}},{"cell_type":"markdown","source":"## AWS S3","metadata":{}},{"cell_type":"markdown","source":"Na etapa de ingestão, o AWS S3 tem a função de passivamente armazenar as mensagens captadas pelo bot do Telegram no seu formato original: JSON.","metadata":{}},{"cell_type":"markdown","source":"## AWS Lambda","metadata":{}},{"cell_type":"markdown","source":"Na etapa de ingestão, o AWS Lambda tem a função de ativamente persistir as mensagens captadas pelo bot do Telegram em um bucket do AWS S3. ","metadata":{}},{"cell_type":"markdown","source":"Código da função:","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport logging\nfrom datetime import datetime, timezone\n\nimport boto3\n\n\ndef lambda_handler(event: dict, context: dict) -> dict:\n\n  '''\n  Recebe uma mensagens do Telegram via AWS API Gateway, verifica no\n  seu conteúdo se foi produzida em um determinado grupo e a escreve, \n  em seu formato original JSON, em um bucket do AWS S3.\n  '''\n\n  # vars de ambiente\n\n  BUCKET = os.environ['AWS_S3_BUCKET']\n  TELEGRAM_CHAT_ID = int(os.environ['TELEGRAM_CHAT_ID'])\n\n  # vars lógicas\n\n  tzinfo = timezone(offset=timedelta(hours=-3))\n  date = datetime.now(tzinfo).strftime('%Y-%m-%d')\n  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n\n  filename = f'{timestamp}.json'\n\n  # código principal\n\n  client = boto3.client('s3')\n  \n  try:\n\n    message = json.loads(event[\"body\"])\n    chat_id = message[\"message\"][\"chat\"][\"id\"]\n\n    if chat_id == TELEGRAM_CHAT_ID:\n\n      with open(f\"/tmp/{filename}\", mode='w', encoding='utf8') as fp:\n        json.dump(message, fp)\n\n      client.upload_file(f'/tmp/{filename}', BUCKET, f'telegram/context_date={date}/{filename}')\n\n  except Exception as exc:\n      logging.error(msg=exc)\n      return dict(statusCode=\"500\")\n\n  else:\n      return dict(statusCode=\"200\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AWS API Gateway","metadata":{}},{"cell_type":"markdown","source":"Na etapa de ingestão, o AWS API Gateway tem a função de receber as mensagens captadas pelo bot do Telegram, enviadas via webhook, e iniciar uma função do AWS Lambda, passando o conteúdo da mensagem no seu parâmetro event.","metadata":{}},{"cell_type":"markdown","source":"# ETL","metadata":{}},{"cell_type":"markdown","source":"No projeto, as mensagens de um único dia, persistidas na camada cru, serão compactas em um único arquivo, orientado a coluna e comprimido, que será persistido em uma camada enriquecida. Além disso, durante este processo, o dado também passará por etapas de *data wrangling*.\n\nPara isso, foi utilizado uma função do `AWS Lambda` como motor de processamento e um *bucket* do `AWS S3` como camada enriquecida para a persistência do dado processado. Para garantir a recorrência, no `AWS Event Bridge` está configurado uma regra como gatilho diáro da função.","metadata":{}},{"cell_type":"markdown","source":"## AWS S3","metadata":{}},{"cell_type":"markdown","source":"Na etapa de ETL, o AWS S3 tem a função de passivamente armazenar as mensagens processadas de um dia em um único arquivo no formato Parquet. ","metadata":{}},{"cell_type":"markdown","source":"## AWS Lambda","metadata":{}},{"cell_type":"markdown","source":"Na etapa de ETL, o AWS Lambda tem a função de ativamente processar as mensagens captadas pelo bot do Telegram, persistidas na camada cru no bucket do AWS S3, e persisti-las na camada enriquecida, também em um bucket do AWS S3","metadata":{}},{"cell_type":"markdown","source":"* Código da função:","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport logging\nfrom datetime import datetime, timedelta, timezone\n\nimport boto3\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\n\ndef lambda_handler(event: dict, context: dict) -> bool:\n\n  '''\n  Diariamente é executado para compactar as diversas mensagensm, no formato\n  JSON, do dia anterior, armazenadas no bucket de dados cru, em um único \n  arquivo no formato PARQUET, armazenando-o no bucket de dados enriquecidos\n  '''\n\n  # vars de ambiente\n\n  RAW_BUCKET = os.environ['AWS_S3_BUCKET']\n  ENRICHED_BUCKET = os.environ['AWS_S3_ENRICHED']\n\n  # vars lógicas\n\n  tzinfo = timezone(offset=timedelta(hours=-3))\n  date = (datetime.now(tzinfo) - timedelta(days=1)).strftime('%Y-%m-%d')\n  timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')\n\n  # código principal\n\n  table = None\n  client = boto3.client('s3')\n\n  try:\n\n      response = client.list_objects_v2(Bucket=RAW_BUCKET, Prefix=f'telegram/context_date={date}')\n\n      for content in response['Contents']:\n\n        key = content['Key']\n        client.download_file(RAW_BUCKET, key, f\"/tmp/{key.split('/')[-1]}\")\n\n        with open(f\"/tmp/{key.split('/')[-1]}\", mode='r', encoding='utf8') as fp:\n\n          data = json.load(fp)\n          data = data[\"message\"]\n\n        parsed_data = parse_data(data=data)\n        iter_table = pa.Table.from_pydict(mapping=parsed_data)\n\n        if table:\n\n          table = pa.concat_tables([table, iter_table])\n\n        else:\n\n          table = iter_table\n          iter_table = None\n          \n      pq.write_table(table=table, where=f'/tmp/{timestamp}.parquet')\n      client.upload_file(f\"/tmp/{timestamp}.parquet\", ENRICHED_BUCKET, f\"telegram/context_date={date}/{timestamp}.parquet\")\n\n      return True\n  \n  except Exception as exc:\n      logging.error(msg=exc)\n      return False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Código do data *data wrangling*:","metadata":{}},{"cell_type":"code","source":"def parse_data(data: dict) -> dict:\n\n  date = datetime.now().strftime('%Y-%m-%d')\n  timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n  parsed_data = dict()\n\n  for key, value in data.items():\n\n      if key == 'from':\n          for k, v in data[key].items():\n              if k in ['id', 'is_bot', 'first_name']:\n                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n\n      elif key == 'chat':\n          for k, v in data[key].items():\n              if k in ['id', 'type']:\n                parsed_data[f\"{key if key == 'chat' else 'user'}_{k}\"] = [v]\n\n      elif key in ['message_id', 'date', 'text']:\n          parsed_data[key] = [value]\n\n  if not 'text' in parsed_data.keys():\n    parsed_data['text'] = [None]\n\n  return parsed_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AWS Event Bridge","metadata":{}},{"cell_type":"markdown","source":"Na etapa de ETL, o AWS Event Bridge tem a função de ativar diariamente a função de ETL do AWS Lambda, funcionando assim como um scheduler.","metadata":{}},{"cell_type":"markdown","source":"# Apresentação","metadata":{}},{"cell_type":"markdown","source":"## AWS Athena","metadata":{}},{"cell_type":"markdown","source":"Na etapa de apresentação, o AWS Athena tem função de entregar o dados através de uma interface SQL para os usuários do sistema analítico. ","metadata":{}},{"cell_type":"code","source":"CREATE EXTERNAL TABLE 'telegram' (\n\t'message_id' bigint,\n\t'user_id' bigint,\n\t'user_is_bot' boolean,\n\t'user_first_name' string,\n\t'chat_id' bigint,\n\t'chat_type'string,\n\t'text' string,\n\t'date' bigint)\nPARTITIONED BY (\n\t'context_date' date)\nROW FORMAT SERDE\n\t'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\nSTORED AS INPUTFORMAT\n\t'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'\nOUTPUT FORMAT \n\t'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'\nLOCATION \n\t's3://<bucket-enriquecido>/'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analytics","metadata":{}},{"cell_type":"markdown","source":"Com o dado disponível, podemos executar a amais variadas consultas analíticas. Alguns exemplos são:","metadata":{}},{"cell_type":"markdown","source":"* Quantidade de mensagens por dia:","metadata":{}},{"cell_type":"code","source":"SELECT \n  user_id, \n  user_first_name, \n  context_date, \n  count(1) AS \"message_amount\" \nFROM \"telegram\" \nGROUP BY \n  user_id, \n  user_first_name, \n  context_date \nORDER BY context_date DESC","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Quantidade de mensagem por usuário por dia:","metadata":{}},{"cell_type":"code","source":"SELECT \n  user_id, \n  user_first_name, \n  context_date,\n  CAST(AVG(length(text)) AS INT) AS \"average_message_length\" \nFROM \"telegram\" \nGROUP BY \n  user_id, \n  user_first_name, \n  context_date \nORDER BY context_date DESC","metadata":{},"execution_count":null,"outputs":[]}]}